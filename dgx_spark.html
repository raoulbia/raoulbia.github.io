<!DOCTYPE html>
<html lang="en">
<head>
      <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>code snippets etc. - DGX Spark</title>
    <link rel="shortcut icon" type="image/png" href="./favicon.png">
    <link rel="shortcut icon" type="image/x-icon" href="./favicon.ico">
    <link rel="stylesheet" href="./theme/css/main.css" type="text/css" />
    <link rel="stylesheet" href="./theme/css/pygments.css" type="text/css" />
    <link rel="stylesheet" href="./static/custom-code.css" type="text/css" />
    <meta name="generator" content="Pelican" />
    <meta name="description" content="" />
    <meta name="author" content="" />





</head>
<body>
    <header>
        <nav>
            <ul>
                <li><a href="./">Home</a></li>
                <li><a href="./archives">Archives</a></li>
            </ul>
        </nav>
        <div class="header_box">
            <h1><a href="./">code snippets etc.</a></h1>
        </div>
    </header>
    <div id="wrapper">
        <div id="content">  <article>
    <header>
      <h2>
        <a href="./dgx_spark.html" rel="bookmark"
           title="Permalink to DGX Spark">DGX Spark</a></h2>
      
    </header>
    <p><br></p>
<h3>Fine-tuning Options on DGX Spark (GB10, 128GB unified memory)</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Framework</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td>NeMo + LoRA (current)</td>
<td>NVIDIA NeMo</td>
<td>Official NVIDIA support, optimized for DGX, proven working</td>
<td>Complex setup, container-based</td>
</tr>
<tr>
<td>Unsloth</td>
<td>HuggingFace-based</td>
<td>2x faster, 60% less memory, simple API</td>
<td>Less NVIDIA optimization</td>
</tr>
<tr>
<td>Axolotl</td>
<td>HuggingFace-based</td>
<td>YAML config, many techniques (LoRA, QLoRA, full)</td>
<td>Medium complexity</td>
</tr>
<tr>
<td>HuggingFace PEFT</td>
<td>Transformers</td>
<td>Most popular, huge community</td>
<td>Manual optimization needed</td>
</tr>
<tr>
<td>LLaMA-Factory</td>
<td>HuggingFace-based</td>
<td>Web UI, no-code option</td>
<td>Less control</td>
</tr>
</tbody>
</table>
<p><br></p>
<h3>GPU Assessment:</h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
<th>Assessment</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPU Util</td>
<td>88%</td>
<td>Good, not bottlenecked</td>
</tr>
<tr>
<td>Temp</td>
<td>68Â°C</td>
<td>Normal</td>
</tr>
<tr>
<td>Power</td>
<td>56W</td>
<td>Moderate</td>
</tr>
</tbody>
</table>
<p>Speed factors (not learning rate):</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Current</th>
<th>Could Speed Up?</th>
</tr>
</thead>
<tbody>
<tr>
<td>local_batch_size</td>
<td>1</td>
<td>Increase to 2-4 if memory allows</td>
</tr>
<tr>
<td>global_batch_size</td>
<td>16</td>
<td>Means 16 gradient accumulation steps</td>
</tr>
<tr>
<td>seq_length</td>
<td>2048</td>
<td>Lower if your data is shorter</td>
</tr>
<tr>
<td>Precision</td>
<td>bf16-mixed</td>
<td>Already optimal</td>
</tr>
</tbody>
</table>
<p>88% utilization is solid. The main bottleneck is local_batch_size: 1 - you're processing 1 sample at a time with 16 accumulation steps. With 128GB unified
  memory, you could likely increase to local_batch_size: 2 or 4 to speed things up ~2-4x.</p>
<p><br></p>
<h3>Misc</h3>
<div class="highlight"><pre><span></span><code>docker<span class="w"> </span>start<span class="w"> </span>vllm-server
docker<span class="w"> </span>logs<span class="w"> </span>-f<span class="w"> </span>--tail<span class="w"> </span><span class="m">50</span><span class="w"> </span>vllm-server
</code></pre></div>

<h2>~/.ssh/config</h2>
<div class="highlight"><pre><span></span><code>Host dgx-spark
    HostName 192.168.1.xx
    User &lt;user-name&gt;
    IdentityFile ~/.ssh/&lt;name-of-pub-ssh-key&gt;
    IdentitiesOnly yes
    LocalForward 8000 localhost:8000
    LocalForward 11434 localhost:11434
</code></pre></div>

<p><br></p>
<h3>SSH Tunnel</h3>
<div class="highlight"><pre><span></span><code>ssh<span class="w"> </span>-N<span class="w"> </span>-L<span class="w"> </span><span class="m">8000</span>:localhost:8000<span class="w"> </span>-L<span class="w"> </span><span class="m">12434</span>:localhost:12434<span class="w"> </span>user@spark-e123.local
</code></pre></div>

<p><br></p>
<h3>Example Roo Code configuration for vLLM:</h3>
<ul>
<li>API Provider: <code>OpenAI Compatible</code></li>
<li>Base URL: <code>http://localhost:8000/v1</code></li>
<li>API Key: <code>not-required</code></li>
<li>Model: <code>Qwen/Qwen2.5-Coder-14B-Instruct</code></li>
</ul>
    <footer>
      <p>Published: <time datetime="2025-11-17T00:00:00+00:00">
        Mon 17 November 2025
      </time></p>
        <p>
          Category: <a href="./category/ai.html">AI</a>
        </p>
    </footer>
  </article>

            <div class="clear"></div>
            <footer>
                <p>
                <a href="https://github.com/jody-frankowski/blue-penguin">Blue Penguin</a> Theme
                &middot;
                Powered by <a href="http://getpelican.com">Pelican</a>
            </footer>
        </div>
        <div class="clear"></div>
    </div>
<script>
// Add copy buttons to all code blocks
document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('pre').forEach(function(pre) {
        // Avoid duplicate buttons
        if (pre.querySelector('.copy-btn')) return;
        var btn = document.createElement('button');
        btn.className = 'copy-btn';
        btn.type = 'button';
        btn.innerText = 'Copy';
        btn.onclick = function() {
            var code = pre.querySelector('code');
            if (code) {
                var text = code.innerText;
                navigator.clipboard.writeText(text).then(function() {
                    btn.innerText = 'Copied!';
                    setTimeout(function() { btn.innerText = 'Copy'; }, 1200);
                });
            }
        };
        pre.appendChild(btn);
        pre.style.position = 'relative';
    });
});
</script>
</body>
</html>